{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "599b8c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f880086",
   "metadata": {},
   "source": [
    "#### Objective\n",
    "House price prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d268da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1f3718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset.data)\n",
    "df.columns = dataset.feature_names\n",
    "df[dataset.target_names[0]] = dataset.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72d27795",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d87e00d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9674bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "def objective_linear(trial):\n",
    "    params = {\n",
    "        'degree': trial.suggest_int('degree', 1, 5)\n",
    "    }\n",
    "    model = Pipeline([\n",
    "        ('poly', PolynomialFeatures(**params)),\n",
    "        ('linear', LinearRegression(fit_intercept=False))\n",
    "    ])\n",
    "    score = cross_val_score(model, X_train, y_train, cv=kf, scoring=make_scorer(mean_squared_error)).mean()\n",
    "    return score\n",
    "\n",
    "def objective_xg(trial):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-5, 1),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-5, 1),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10)\n",
    "    }\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=kf, scoring=make_scorer(mean_squared_error)).mean()\n",
    "    return score\n",
    "\n",
    "def objective_svr(trial):\n",
    "    params = {\n",
    "        'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly']),\n",
    "        'C': trial.suggest_float('C', 0.1, 10),\n",
    "        'epsilon': trial.suggest_float('epsilon', 0.01, 0.1),\n",
    "    }\n",
    "    model = SVR(**params)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=kf, scoring=make_scorer(mean_squared_error)).mean()\n",
    "    return score\n",
    "\n",
    "def objective_decision_reg(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "        'min_samples_split': trial.suggest_float('min_samples_split', 0.1, 1),\n",
    "        'min_samples_leaf': trial.suggest_float('min_samples_leaf', 0.1, 0.5),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2', None])\n",
    "    }\n",
    "    model = DecisionTreeRegressor(**params)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=kf, scoring=make_scorer(mean_squared_error)).mean()\n",
    "    return score\n",
    "\n",
    "def objective_rf_reg(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 32, log=True),\n",
    "        'min_samples_split': trial.suggest_float('min_samples_split', 0.1, 1),\n",
    "        'min_samples_leaf': trial.suggest_float('min_samples_leaf', 0.1, 0.5),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2', None])\n",
    "    }\n",
    "    model = RandomForestRegressor(**params)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=kf, scoring=make_scorer(mean_squared_error)).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93346a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 16:39:08,378] A new study created in memory with name: no-name-54ac31d2-3cb5-4c37-ae94-5f076cbd3ada\n",
      "[I 2023-12-27 16:39:21,516] Trial 0 finished with value: 80447209847.1964 and parameters: {'degree': 5}. Best is trial 0 with value: 80447209847.1964.\n",
      "[I 2023-12-27 16:39:23,411] Trial 1 finished with value: 7697552590.333864 and parameters: {'degree': 4}. Best is trial 1 with value: 7697552590.333864.\n",
      "[I 2023-12-27 16:39:26,000] Trial 2 finished with value: 7697552590.333864 and parameters: {'degree': 4}. Best is trial 1 with value: 7697552590.333864.\n",
      "[I 2023-12-27 16:39:28,142] Trial 3 finished with value: 7697552590.333864 and parameters: {'degree': 4}. Best is trial 1 with value: 7697552590.333864.\n",
      "[I 2023-12-27 16:39:31,083] Trial 4 finished with value: 7697552590.333864 and parameters: {'degree': 4}. Best is trial 1 with value: 7697552590.333864.\n",
      "[I 2023-12-27 16:39:31,208] Trial 5 finished with value: 3.8365757187337417 and parameters: {'degree': 2}. Best is trial 5 with value: 3.8365757187337417.\n",
      "[I 2023-12-27 16:39:33,399] Trial 6 finished with value: 7697552590.333864 and parameters: {'degree': 4}. Best is trial 5 with value: 3.8365757187337417.\n",
      "[I 2023-12-27 16:39:35,618] Trial 7 finished with value: 7697552590.333864 and parameters: {'degree': 4}. Best is trial 5 with value: 3.8365757187337417.\n",
      "[I 2023-12-27 16:39:35,740] Trial 8 finished with value: 3.8365757187337417 and parameters: {'degree': 2}. Best is trial 5 with value: 3.8365757187337417.\n",
      "[I 2023-12-27 16:39:35,765] Trial 9 finished with value: 0.5193270208432356 and parameters: {'degree': 1}. Best is trial 9 with value: 0.5193270208432356.\n",
      "[I 2023-12-27 16:39:35,800] Trial 10 finished with value: 0.5193270208432356 and parameters: {'degree': 1}. Best is trial 9 with value: 0.5193270208432356.\n",
      "[I 2023-12-27 16:39:35,832] Trial 11 finished with value: 0.5193270208432356 and parameters: {'degree': 1}. Best is trial 9 with value: 0.5193270208432356.\n",
      "[I 2023-12-27 16:39:35,862] Trial 12 finished with value: 0.5193270208432356 and parameters: {'degree': 1}. Best is trial 9 with value: 0.5193270208432356.\n",
      "[I 2023-12-27 16:39:36,021] Trial 13 finished with value: 3.8365757187337417 and parameters: {'degree': 2}. Best is trial 9 with value: 0.5193270208432356.\n",
      "[I 2023-12-27 16:39:36,086] Trial 14 finished with value: 0.5193270208432356 and parameters: {'degree': 1}. Best is trial 9 with value: 0.5193270208432356.\n",
      "[I 2023-12-27 16:39:36,202] Trial 15 finished with value: 3.8365757187337417 and parameters: {'degree': 2}. Best is trial 9 with value: 0.5193270208432356.\n",
      "[I 2023-12-27 16:39:36,913] Trial 16 finished with value: 542180.5337066596 and parameters: {'degree': 3}. Best is trial 9 with value: 0.5193270208432356.\n",
      "[I 2023-12-27 16:39:36,955] Trial 17 finished with value: 0.5193270208432356 and parameters: {'degree': 1}. Best is trial 9 with value: 0.5193270208432356.\n",
      "[I 2023-12-27 16:39:37,615] Trial 18 finished with value: 542180.5337066596 and parameters: {'degree': 3}. Best is trial 9 with value: 0.5193270208432356.\n",
      "[I 2023-12-27 16:39:38,248] Trial 19 finished with value: 542180.5337066596 and parameters: {'degree': 3}. Best is trial 9 with value: 0.5193270208432356.\n",
      "/var/folders/zp/kk11qt0x5hv0f57zgwg0h65r0000gn/T/ipykernel_15060/2777161657.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_err = df_err.append({'Model': func.__name__, 'Best error': study.best_value, 'Best params': study.best_params}, ignore_index=True)\n",
      "[I 2023-12-27 16:39:38,257] A new study created in memory with name: no-name-4900ca30-2971-4881-a0d0-3e51e4cbd6f2\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:39:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:39:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:39:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:39:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:39:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2023-12-27 16:39:46,799] Trial 0 finished with value: 0.8249993109131406 and parameters: {'booster': 'gblinear', 'learning_rate': 0.19707611673286743, 'max_depth': 3, 'subsample': 0.6469342130042737, 'colsample_bytree': 0.8490713420872958, 'lambda': 0.4388950408337401, 'alpha': 0.5929218985898457, 'min_child_weight': 10}. Best is trial 0 with value: 0.8249993109131406.\n",
      "[I 2023-12-27 16:40:38,878] Trial 1 finished with value: 0.21413791608290295 and parameters: {'booster': 'dart', 'learning_rate': 0.13573863710994866, 'max_depth': 8, 'subsample': 0.9368683388595596, 'colsample_bytree': 0.8170452833230551, 'lambda': 0.5100327465196506, 'alpha': 0.12260985246666928, 'min_child_weight': 5}. Best is trial 1 with value: 0.21413791608290295.\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:40:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:40:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:40:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:40:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:40:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2023-12-27 16:40:39,278] Trial 2 finished with value: 1.1441328853739718 and parameters: {'booster': 'gblinear', 'learning_rate': 0.021918287669225853, 'max_depth': 9, 'subsample': 0.9555786795935568, 'colsample_bytree': 0.722166891063724, 'lambda': 0.35719380634825876, 'alpha': 0.6510999877956155, 'min_child_weight': 4}. Best is trial 1 with value: 0.21413791608290295.\n",
      "[I 2023-12-27 16:41:06,033] Trial 3 finished with value: 0.21263216515371175 and parameters: {'booster': 'dart', 'learning_rate': 0.08522051817482974, 'max_depth': 9, 'subsample': 0.9236117539017206, 'colsample_bytree': 0.8075175535531338, 'lambda': 0.7043380189617489, 'alpha': 0.37098297785081646, 'min_child_weight': 2}. Best is trial 3 with value: 0.21263216515371175.\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2023-12-27 16:41:06,498] Trial 4 finished with value: 0.8679654283930407 and parameters: {'booster': 'gblinear', 'learning_rate': 0.18129562658809611, 'max_depth': 3, 'subsample': 0.5325714251099205, 'colsample_bytree': 0.8261435980334773, 'lambda': 0.927243539986371, 'alpha': 0.6032141501652902, 'min_child_weight': 2}. Best is trial 3 with value: 0.21263216515371175.\n",
      "[I 2023-12-27 16:41:08,773] Trial 5 finished with value: 0.22461150143540526 and parameters: {'booster': 'gbtree', 'learning_rate': 0.17524574712325128, 'max_depth': 7, 'subsample': 0.628956324814907, 'colsample_bytree': 0.6468272192175188, 'lambda': 0.16984801943611644, 'alpha': 0.8003652931309297, 'min_child_weight': 3}. Best is trial 3 with value: 0.21263216515371175.\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2023-12-27 16:41:09,186] Trial 6 finished with value: 0.7082328784709944 and parameters: {'booster': 'gblinear', 'learning_rate': 0.14453047079886422, 'max_depth': 7, 'subsample': 0.5066564679067876, 'colsample_bytree': 0.740381169854009, 'lambda': 0.49095002066374166, 'alpha': 0.12323339666874235, 'min_child_weight': 5}. Best is trial 3 with value: 0.21263216515371175.\n",
      "[I 2023-12-27 16:41:33,912] Trial 7 finished with value: 0.2339005630873107 and parameters: {'booster': 'dart', 'learning_rate': 0.16176673442762654, 'max_depth': 10, 'subsample': 0.9293080265528741, 'colsample_bytree': 0.5660728586268371, 'lambda': 0.8418321908938476, 'alpha': 0.06432446978020742, 'min_child_weight': 2}. Best is trial 3 with value: 0.21263216515371175.\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2023-12-27 16:41:34,275] Trial 8 finished with value: 0.9205936460394142 and parameters: {'booster': 'gblinear', 'learning_rate': 0.2856285333429796, 'max_depth': 6, 'subsample': 0.8422101086349947, 'colsample_bytree': 0.885992028305306, 'lambda': 0.5749453250173123, 'alpha': 0.8122238122765393, 'min_child_weight': 3}. Best is trial 3 with value: 0.21263216515371175.\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:41:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2023-12-27 16:41:34,651] Trial 9 finished with value: 0.7717179824047287 and parameters: {'booster': 'gblinear', 'learning_rate': 0.22270295231735765, 'max_depth': 6, 'subsample': 0.8873736500347289, 'colsample_bytree': 0.9084532094590873, 'lambda': 0.7980887099366, 'alpha': 0.39122785622460055, 'min_child_weight': 4}. Best is trial 3 with value: 0.21263216515371175.\n",
      "[I 2023-12-27 16:42:01,066] Trial 10 finished with value: 0.21536786441120545 and parameters: {'booster': 'dart', 'learning_rate': 0.07886224778423284, 'max_depth': 10, 'subsample': 0.9971667241706889, 'colsample_bytree': 0.996113911294581, 'lambda': 0.6892231031000063, 'alpha': 0.3967916158898807, 'min_child_weight': 8}. Best is trial 3 with value: 0.21263216515371175.\n",
      "[I 2023-12-27 16:42:25,962] Trial 11 finished with value: 0.212740760938572 and parameters: {'booster': 'dart', 'learning_rate': 0.09955823989443008, 'max_depth': 8, 'subsample': 0.8313490002538277, 'colsample_bytree': 0.7761377122527524, 'lambda': 0.6490795474540008, 'alpha': 0.23077015261641828, 'min_child_weight': 7}. Best is trial 3 with value: 0.21263216515371175.\n",
      "[I 2023-12-27 16:42:51,378] Trial 12 finished with value: 0.21258423058587206 and parameters: {'booster': 'dart', 'learning_rate': 0.0897756875591105, 'max_depth': 8, 'subsample': 0.8182283761327291, 'colsample_bytree': 0.7022052160044676, 'lambda': 0.7008253701931766, 'alpha': 0.26576879851376356, 'min_child_weight': 7}. Best is trial 12 with value: 0.21258423058587206.\n",
      "[I 2023-12-27 16:43:17,097] Trial 13 finished with value: 0.21505815686599009 and parameters: {'booster': 'dart', 'learning_rate': 0.06148487144041284, 'max_depth': 9, 'subsample': 0.7509457514851808, 'colsample_bytree': 0.6676706371817407, 'lambda': 0.9993769561828358, 'alpha': 0.3090450403422442, 'min_child_weight': 7}. Best is trial 12 with value: 0.21258423058587206.\n",
      "[I 2023-12-27 16:43:19,385] Trial 14 finished with value: 0.48603523735155374 and parameters: {'booster': 'gbtree', 'learning_rate': 0.011761789979863504, 'max_depth': 8, 'subsample': 0.8018244305103521, 'colsample_bytree': 0.5771912416975478, 'lambda': 0.7170106468528021, 'alpha': 0.4585777930366294, 'min_child_weight': 1}. Best is trial 12 with value: 0.21258423058587206.\n",
      "[I 2023-12-27 16:43:42,611] Trial 15 finished with value: 0.23461829580156227 and parameters: {'booster': 'dart', 'learning_rate': 0.10742181223436031, 'max_depth': 5, 'subsample': 0.871906165501443, 'colsample_bytree': 0.7228346035909676, 'lambda': 0.7972199705970322, 'alpha': 0.25624324477198146, 'min_child_weight': 9}. Best is trial 12 with value: 0.21258423058587206.\n",
      "[I 2023-12-27 16:44:08,659] Trial 16 finished with value: 0.21665686525231737 and parameters: {'booster': 'dart', 'learning_rate': 0.055011490135478694, 'max_depth': 9, 'subsample': 0.7851624492917852, 'colsample_bytree': 0.6414118683810592, 'lambda': 0.6269752251337302, 'alpha': 0.02016921434933533, 'min_child_weight': 7}. Best is trial 12 with value: 0.21258423058587206.\n",
      "[I 2023-12-27 16:44:09,836] Trial 17 finished with value: 0.2378145407044367 and parameters: {'booster': 'gbtree', 'learning_rate': 0.11408584317547216, 'max_depth': 5, 'subsample': 0.880479569103135, 'colsample_bytree': 0.5034105210704688, 'lambda': 0.7511695384399272, 'alpha': 0.9798905547929413, 'min_child_weight': 6}. Best is trial 12 with value: 0.21258423058587206.\n",
      "[I 2023-12-27 16:44:38,110] Trial 18 finished with value: 0.21751962151218657 and parameters: {'booster': 'dart', 'learning_rate': 0.04843412272943823, 'max_depth': 10, 'subsample': 0.740285569882482, 'colsample_bytree': 0.7641814306599617, 'lambda': 0.8877307372229941, 'alpha': 0.30276978580648806, 'min_child_weight': 1}. Best is trial 12 with value: 0.21258423058587206.\n",
      "[I 2023-12-27 16:45:03,210] Trial 19 finished with value: 0.21317856364008575 and parameters: {'booster': 'dart', 'learning_rate': 0.08542533698352607, 'max_depth': 8, 'subsample': 0.97954244929045, 'colsample_bytree': 0.6926659872641773, 'lambda': 0.5919731221878588, 'alpha': 0.18226103387871503, 'min_child_weight': 6}. Best is trial 12 with value: 0.21258423058587206.\n",
      "/var/folders/zp/kk11qt0x5hv0f57zgwg0h65r0000gn/T/ipykernel_15060/2777161657.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_err = df_err.append({'Model': func.__name__, 'Best error': study.best_value, 'Best params': study.best_params}, ignore_index=True)\n",
      "[I 2023-12-27 16:45:03,211] A new study created in memory with name: no-name-79d9f75c-16af-4416-a8fb-7737eaecda4f\n",
      "[I 2023-12-27 16:45:03,232] Trial 0 finished with value: 1.2457046669854144 and parameters: {'max_depth': 2, 'min_samples_split': 0.6845386500858329, 'min_samples_leaf': 0.4463391064631319, 'max_features': 'sqrt'}. Best is trial 0 with value: 1.2457046669854144.\n",
      "[I 2023-12-27 16:45:03,300] Trial 1 finished with value: 0.8146263698779503 and parameters: {'max_depth': 9, 'min_samples_split': 0.10290557125349825, 'min_samples_leaf': 0.209674526958112, 'max_features': None}. Best is trial 1 with value: 0.8146263698779503.\n",
      "[I 2023-12-27 16:45:03,322] Trial 2 finished with value: 1.1554236652962513 and parameters: {'max_depth': 7, 'min_samples_split': 0.5342651899707132, 'min_samples_leaf': 0.4154700305865695, 'max_features': 'log2'}. Best is trial 1 with value: 0.8146263698779503.\n",
      "[I 2023-12-27 16:45:03,365] Trial 3 finished with value: 0.9406107970923865 and parameters: {'max_depth': 8, 'min_samples_split': 0.2963018322238687, 'min_samples_leaf': 0.3324211547185367, 'max_features': None}. Best is trial 1 with value: 0.8146263698779503.\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "[I 2023-12-27 16:45:03,433] Trial 4 finished with value: 0.8533559547814047 and parameters: {'max_depth': 4, 'min_samples_split': 0.5109192963985192, 'min_samples_leaf': 0.27441482968990494, 'max_features': 'auto'}. Best is trial 1 with value: 0.8146263698779503.\n",
      "[I 2023-12-27 16:45:03,454] Trial 5 finished with value: 1.2245807238892772 and parameters: {'max_depth': 6, 'min_samples_split': 0.18286672124515682, 'min_samples_leaf': 0.3311670891527454, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.8146263698779503.\n",
      "[I 2023-12-27 16:45:03,472] Trial 6 finished with value: 1.2229765224627829 and parameters: {'max_depth': 4, 'min_samples_split': 0.851097313522041, 'min_samples_leaf': 0.4411737738317653, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.8146263698779503.\n",
      "[I 2023-12-27 16:45:03,504] Trial 7 finished with value: 1.0329502236014205 and parameters: {'max_depth': 2, 'min_samples_split': 0.4456707164625225, 'min_samples_leaf': 0.24565876148346866, 'max_features': 'log2'}. Best is trial 1 with value: 0.8146263698779503.\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "[I 2023-12-27 16:45:03,548] Trial 8 finished with value: 0.928638617824791 and parameters: {'max_depth': 8, 'min_samples_split': 0.992645006741608, 'min_samples_leaf': 0.29026196880013017, 'max_features': 'auto'}. Best is trial 1 with value: 0.8146263698779503.\n",
      "[I 2023-12-27 16:45:03,591] Trial 9 finished with value: 0.9524793689691269 and parameters: {'max_depth': 7, 'min_samples_split': 0.6328058873065294, 'min_samples_leaf': 0.3987119797887561, 'max_features': None}. Best is trial 1 with value: 0.8146263698779503.\n",
      "[I 2023-12-27 16:45:03,710] Trial 10 finished with value: 0.7425575169282821 and parameters: {'max_depth': 10, 'min_samples_split': 0.24535694643008044, 'min_samples_leaf': 0.14625262220833968, 'max_features': None}. Best is trial 10 with value: 0.7425575169282821.\n",
      "[I 2023-12-27 16:45:03,838] Trial 11 finished with value: 0.7333150165438301 and parameters: {'max_depth': 10, 'min_samples_split': 0.11370551520446187, 'min_samples_leaf': 0.13500318933527497, 'max_features': None}. Best is trial 11 with value: 0.7333150165438301.\n",
      "[I 2023-12-27 16:45:03,984] Trial 12 finished with value: 0.7330245894344476 and parameters: {'max_depth': 10, 'min_samples_split': 0.2747340725088608, 'min_samples_leaf': 0.1297852142773132, 'max_features': None}. Best is trial 12 with value: 0.7330245894344476.\n",
      "[I 2023-12-27 16:45:04,084] Trial 13 finished with value: 0.7400566042898797 and parameters: {'max_depth': 10, 'min_samples_split': 0.3331422160904068, 'min_samples_leaf': 0.11982839860350643, 'max_features': None}. Best is trial 12 with value: 0.7330245894344476.\n",
      "[I 2023-12-27 16:45:04,184] Trial 14 finished with value: 0.7460318682304052 and parameters: {'max_depth': 10, 'min_samples_split': 0.10172956057128707, 'min_samples_leaf': 0.16934360392116496, 'max_features': None}. Best is trial 12 with value: 0.7330245894344476.\n",
      "[I 2023-12-27 16:45:04,283] Trial 15 finished with value: 0.73597414915905 and parameters: {'max_depth': 9, 'min_samples_split': 0.35674141899370965, 'min_samples_leaf': 0.10606533199162405, 'max_features': None}. Best is trial 12 with value: 0.7330245894344476.\n",
      "[I 2023-12-27 16:45:04,374] Trial 16 finished with value: 0.7736119281607619 and parameters: {'max_depth': 6, 'min_samples_split': 0.2143630363400576, 'min_samples_leaf': 0.19216470581364167, 'max_features': None}. Best is trial 12 with value: 0.7330245894344476.\n",
      "[I 2023-12-27 16:45:04,423] Trial 17 finished with value: 1.0038765125162716 and parameters: {'max_depth': 9, 'min_samples_split': 0.41321689131535017, 'min_samples_leaf': 0.10241494098381962, 'max_features': 'log2'}. Best is trial 12 with value: 0.7330245894344476.\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "[I 2023-12-27 16:45:04,522] Trial 18 finished with value: 0.7438365635463151 and parameters: {'max_depth': 8, 'min_samples_split': 0.1795438652338751, 'min_samples_leaf': 0.14973542248451532, 'max_features': 'auto'}. Best is trial 12 with value: 0.7330245894344476.\n",
      "[I 2023-12-27 16:45:04,593] Trial 19 finished with value: 0.8169808318434777 and parameters: {'max_depth': 4, 'min_samples_split': 0.2830233705751326, 'min_samples_leaf': 0.21889210599238348, 'max_features': None}. Best is trial 12 with value: 0.7330245894344476.\n",
      "/var/folders/zp/kk11qt0x5hv0f57zgwg0h65r0000gn/T/ipykernel_15060/2777161657.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_err = df_err.append({'Model': func.__name__, 'Best error': study.best_value, 'Best params': study.best_params}, ignore_index=True)\n",
      "[I 2023-12-27 16:45:04,594] A new study created in memory with name: no-name-a080f76d-bd9d-4835-9516-c6fad1c8e06d\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "[I 2023-12-27 16:45:04,870] Trial 0 finished with value: 1.3368726918345568 and parameters: {'n_estimators': 81, 'max_depth': 20, 'min_samples_split': 0.5038082887283031, 'min_samples_leaf': 0.4233439930903442, 'max_features': 'auto'}. Best is trial 0 with value: 1.3368726918345568.\n",
      "[I 2023-12-27 16:45:04,977] Trial 1 finished with value: 1.336848936362034 and parameters: {'n_estimators': 31, 'max_depth': 24, 'min_samples_split': 0.723461995171538, 'min_samples_leaf': 0.19395576079466054, 'max_features': 'sqrt'}. Best is trial 1 with value: 1.336848936362034.\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "[I 2023-12-27 16:45:08,298] Trial 2 finished with value: 0.7987824650904237 and parameters: {'n_estimators': 78, 'max_depth': 7, 'min_samples_split': 0.39740946130463145, 'min_samples_leaf': 0.12314338929358914, 'max_features': 'auto'}. Best is trial 2 with value: 0.7987824650904237.\n",
      "[I 2023-12-27 16:45:08,379] Trial 3 finished with value: 1.3368709457918169 and parameters: {'n_estimators': 16, 'max_depth': 2, 'min_samples_split': 0.44945145584360585, 'min_samples_leaf': 0.4117778943142181, 'max_features': None}. Best is trial 2 with value: 0.7987824650904237.\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "[I 2023-12-27 16:45:08,686] Trial 4 finished with value: 1.3368772796762325 and parameters: {'n_estimators': 78, 'max_depth': 3, 'min_samples_split': 0.7930198490445691, 'min_samples_leaf': 0.45058840357287666, 'max_features': 'auto'}. Best is trial 2 with value: 0.7987824650904237.\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "[I 2023-12-27 16:45:08,740] Trial 5 finished with value: 1.3368379785664395 and parameters: {'n_estimators': 10, 'max_depth': 28, 'min_samples_split': 0.9363115817589988, 'min_samples_leaf': 0.2961138105977846, 'max_features': 'auto'}. Best is trial 2 with value: 0.7987824650904237.\n",
      "[I 2023-12-27 16:45:09,821] Trial 6 finished with value: 0.9760834041863365 and parameters: {'n_estimators': 45, 'max_depth': 6, 'min_samples_split': 0.4253891083055874, 'min_samples_leaf': 0.31067564234612355, 'max_features': None}. Best is trial 2 with value: 0.7987824650904237.\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/abbywinder/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "[I 2023-12-27 16:45:09,974] Trial 7 finished with value: 1.3368822040821955 and parameters: {'n_estimators': 39, 'max_depth': 7, 'min_samples_split': 0.13693161921170885, 'min_samples_leaf': 0.48513331403054477, 'max_features': 'auto'}. Best is trial 2 with value: 0.7987824650904237.\n",
      "[I 2023-12-27 16:45:10,430] Trial 8 finished with value: 1.0951014659207086 and parameters: {'n_estimators': 49, 'max_depth': 11, 'min_samples_split': 0.6262436193843921, 'min_samples_leaf': 0.22355215717239743, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7987824650904237.\n",
      "[I 2023-12-27 16:45:10,695] Trial 9 finished with value: 1.3368637226322782 and parameters: {'n_estimators': 81, 'max_depth': 4, 'min_samples_split': 0.881426169443435, 'min_samples_leaf': 0.2155998203642113, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7987824650904237.\n",
      "[I 2023-12-27 16:45:12,683] Trial 10 finished with value: 0.8314836096183524 and parameters: {'n_estimators': 99, 'max_depth': 12, 'min_samples_split': 0.2623340074407548, 'min_samples_leaf': 0.13934431855103072, 'max_features': 'log2'}. Best is trial 2 with value: 0.7987824650904237.\n",
      "[I 2023-12-27 16:45:14,854] Trial 11 finished with value: 0.7744772145433599 and parameters: {'n_estimators': 99, 'max_depth': 10, 'min_samples_split': 0.27085125824502015, 'min_samples_leaf': 0.10829079732024931, 'max_features': 'log2'}. Best is trial 11 with value: 0.7744772145433599.\n",
      "[I 2023-12-27 16:45:16,974] Trial 12 finished with value: 0.780088097642152 and parameters: {'n_estimators': 98, 'max_depth': 10, 'min_samples_split': 0.324304671303809, 'min_samples_leaf': 0.10487889008405561, 'max_features': 'log2'}. Best is trial 11 with value: 0.7744772145433599.\n",
      "[I 2023-12-27 16:45:19,166] Trial 13 finished with value: 0.7492026762813017 and parameters: {'n_estimators': 97, 'max_depth': 14, 'min_samples_split': 0.26825372631231836, 'min_samples_leaf': 0.10070532116681839, 'max_features': 'log2'}. Best is trial 13 with value: 0.7492026762813017.\n",
      "[I 2023-12-27 16:45:20,263] Trial 14 finished with value: 0.897699135857643 and parameters: {'n_estimators': 66, 'max_depth': 15, 'min_samples_split': 0.11123711625343141, 'min_samples_leaf': 0.16403835847576134, 'max_features': 'log2'}. Best is trial 13 with value: 0.7492026762813017.\n",
      "[I 2023-12-27 16:45:21,735] Trial 15 finished with value: 0.7593714000222878 and parameters: {'n_estimators': 63, 'max_depth': 18, 'min_samples_split': 0.24266856503524234, 'min_samples_leaf': 0.10721972508729023, 'max_features': 'log2'}. Best is trial 13 with value: 0.7492026762813017.\n",
      "[I 2023-12-27 16:45:22,850] Trial 16 finished with value: 0.8844644602714155 and parameters: {'n_estimators': 65, 'max_depth': 31, 'min_samples_split': 0.2009521479849366, 'min_samples_leaf': 0.1631027626268407, 'max_features': 'log2'}. Best is trial 13 with value: 0.7492026762813017.\n",
      "[I 2023-12-27 16:45:23,900] Trial 17 finished with value: 0.8989043456941672 and parameters: {'n_estimators': 62, 'max_depth': 17, 'min_samples_split': 0.3408500022577034, 'min_samples_leaf': 0.16598243243814265, 'max_features': 'log2'}. Best is trial 13 with value: 0.7492026762813017.\n",
      "[I 2023-12-27 16:45:25,942] Trial 18 finished with value: 0.7567605119241914 and parameters: {'n_estimators': 88, 'max_depth': 20, 'min_samples_split': 0.209221647382672, 'min_samples_leaf': 0.11319976644640024, 'max_features': 'log2'}. Best is trial 13 with value: 0.7492026762813017.\n",
      "[I 2023-12-27 16:45:26,955] Trial 19 finished with value: 1.0490847220958825 and parameters: {'n_estimators': 90, 'max_depth': 23, 'min_samples_split': 0.55042102152016, 'min_samples_leaf': 0.23615963943507817, 'max_features': 'log2'}. Best is trial 13 with value: 0.7492026762813017.\n",
      "/var/folders/zp/kk11qt0x5hv0f57zgwg0h65r0000gn/T/ipykernel_15060/2777161657.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_err = df_err.append({'Model': func.__name__, 'Best error': study.best_value, 'Best params': study.best_params}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_err = pd.DataFrame({'Model': [], 'Best error': [], 'Best params': []})\n",
    "\n",
    "objective_funcs = [objective_linear, objective_xg, objective_decision_reg, objective_rf_reg]\n",
    "# SVR removed due to slow training - would run on GPU if possible\n",
    "# objective_funcs = [objective_linear, objective_xg, objective_svr, objective_decision_reg, objective_rf_reg]\n",
    "for func in objective_funcs:\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(func, n_trials=20)\n",
    "    df_err = df_err.append({'Model': func.__name__, 'Best error': study.best_value, 'Best params': study.best_params}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95002184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best error</th>\n",
       "      <th>Best params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>objective_linear</td>\n",
       "      <td>0.519327</td>\n",
       "      <td>{'degree': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>objective_xg</td>\n",
       "      <td>0.212584</td>\n",
       "      <td>{'booster': 'dart', 'learning_rate': 0.0897756...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>objective_decision_reg</td>\n",
       "      <td>0.733025</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 0.27473...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>objective_rf_reg</td>\n",
       "      <td>0.749203</td>\n",
       "      <td>{'n_estimators': 97, 'max_depth': 14, 'min_sam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Best error  \\\n",
       "0        objective_linear    0.519327   \n",
       "1            objective_xg    0.212584   \n",
       "2  objective_decision_reg    0.733025   \n",
       "3        objective_rf_reg    0.749203   \n",
       "\n",
       "                                         Best params  \n",
       "0                                      {'degree': 1}  \n",
       "1  {'booster': 'dart', 'learning_rate': 0.0897756...  \n",
       "2  {'max_depth': 10, 'min_samples_split': 0.27473...  \n",
       "3  {'n_estimators': 97, 'max_depth': 14, 'min_sam...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6fe10dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model                                               objective_xg\n",
       "Best error                                              0.212584\n",
       "Best params    {'booster': 'dart', 'learning_rate': 0.0897756...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_model = df_err.iloc[df_err['Best error'].idxmin()]\n",
    "chosen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3dab5ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2080348240466048"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(**chosen_model['Best params'])\n",
    "model.fit(X_train, y_train)\n",
    "model.save_model('0001.json')\n",
    "y_pred_test = model.predict(X_test)\n",
    "rmse_test = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28db4da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedVal</th>\n",
       "      <th>PredVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20046</th>\n",
       "      <td>1.6812</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.192201</td>\n",
       "      <td>1.022284</td>\n",
       "      <td>1392.0</td>\n",
       "      <td>3.877437</td>\n",
       "      <td>36.06</td>\n",
       "      <td>-119.01</td>\n",
       "      <td>0.47700</td>\n",
       "      <td>0.486708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>2.5313</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.039384</td>\n",
       "      <td>1.193493</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>2.679795</td>\n",
       "      <td>35.14</td>\n",
       "      <td>-119.46</td>\n",
       "      <td>0.45800</td>\n",
       "      <td>0.963284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15663</th>\n",
       "      <td>3.4801</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.977155</td>\n",
       "      <td>1.185877</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>1.360332</td>\n",
       "      <td>37.80</td>\n",
       "      <td>-122.44</td>\n",
       "      <td>5.00001</td>\n",
       "      <td>5.078151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20484</th>\n",
       "      <td>5.7376</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.163636</td>\n",
       "      <td>1.020202</td>\n",
       "      <td>1705.0</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>34.28</td>\n",
       "      <td>-118.72</td>\n",
       "      <td>2.18600</td>\n",
       "      <td>2.393430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9814</th>\n",
       "      <td>3.7250</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.492991</td>\n",
       "      <td>1.028037</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>2.483645</td>\n",
       "      <td>36.62</td>\n",
       "      <td>-121.93</td>\n",
       "      <td>2.78000</td>\n",
       "      <td>2.168953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15362</th>\n",
       "      <td>4.6050</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.002212</td>\n",
       "      <td>1.066372</td>\n",
       "      <td>1351.0</td>\n",
       "      <td>2.988938</td>\n",
       "      <td>33.36</td>\n",
       "      <td>-117.22</td>\n",
       "      <td>2.63300</td>\n",
       "      <td>2.482697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16623</th>\n",
       "      <td>2.7266</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.131915</td>\n",
       "      <td>1.256738</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>2.340426</td>\n",
       "      <td>35.36</td>\n",
       "      <td>-120.83</td>\n",
       "      <td>2.66800</td>\n",
       "      <td>1.767710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18086</th>\n",
       "      <td>9.2298</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.237676</td>\n",
       "      <td>0.947183</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>2.790493</td>\n",
       "      <td>37.31</td>\n",
       "      <td>-122.05</td>\n",
       "      <td>5.00001</td>\n",
       "      <td>4.763497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>2.7850</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.289030</td>\n",
       "      <td>0.983122</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>2.588608</td>\n",
       "      <td>36.77</td>\n",
       "      <td>-119.76</td>\n",
       "      <td>0.72300</td>\n",
       "      <td>0.699229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3665</th>\n",
       "      <td>3.5521</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.988839</td>\n",
       "      <td>1.033482</td>\n",
       "      <td>1671.0</td>\n",
       "      <td>3.729911</td>\n",
       "      <td>34.22</td>\n",
       "      <td>-118.37</td>\n",
       "      <td>1.51500</td>\n",
       "      <td>1.829422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4128 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "20046  1.6812      25.0  4.192201   1.022284      1392.0  3.877437     36.06   \n",
       "3024   2.5313      30.0  5.039384   1.193493      1565.0  2.679795     35.14   \n",
       "15663  3.4801      52.0  3.977155   1.185877      1310.0  1.360332     37.80   \n",
       "20484  5.7376      17.0  6.163636   1.020202      1705.0  3.444444     34.28   \n",
       "9814   3.7250      34.0  5.492991   1.028037      1063.0  2.483645     36.62   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "15362  4.6050      16.0  7.002212   1.066372      1351.0  2.988938     33.36   \n",
       "16623  2.7266      28.0  6.131915   1.256738      1650.0  2.340426     35.36   \n",
       "18086  9.2298      25.0  7.237676   0.947183      1585.0  2.790493     37.31   \n",
       "2144   2.7850      36.0  5.289030   0.983122      1227.0  2.588608     36.77   \n",
       "3665   3.5521      17.0  3.988839   1.033482      1671.0  3.729911     34.22   \n",
       "\n",
       "       Longitude   MedVal   PredVal  \n",
       "20046    -119.01  0.47700  0.486708  \n",
       "3024     -119.46  0.45800  0.963284  \n",
       "15663    -122.44  5.00001  5.078151  \n",
       "20484    -118.72  2.18600  2.393430  \n",
       "9814     -121.93  2.78000  2.168953  \n",
       "...          ...      ...       ...  \n",
       "15362    -117.22  2.63300  2.482697  \n",
       "16623    -120.83  2.66800  1.767710  \n",
       "18086    -122.05  5.00001  4.763497  \n",
       "2144     -119.76  0.72300  0.699229  \n",
       "3665     -118.37  1.51500  1.829422  \n",
       "\n",
       "[4128 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = X_test.copy()\n",
    "df_results['MedVal'] = y_test\n",
    "df_results['PredVal'] = y_pred_test\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e356a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.7877772], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    'MedInc': [8.7038],\n",
    "    'HouseAge': [10.0],\n",
    "    'AveRooms': [5.037594],\n",
    "    'AveBedrms': [5.982048],\n",
    "    'Population': [1000.0],\n",
    "    'AveOccup': [4.04739],\n",
    "    'Latitude': [36.0],\n",
    "    'Longitude': [-120.04]\n",
    "})\n",
    "\n",
    "prediction = model.predict(new_data)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ad202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
